# ComfyUIç¤¾åŒºç‰ˆ

>**å…è´£å£°æ˜ï¼š**æœ¬æœåŠ¡ç”±ç¬¬ä¸‰æ–¹æä¾›ï¼Œæˆ‘ä»¬å°½åŠ›ç¡®ä¿å…¶å®‰å…¨æ€§ã€å‡†ç¡®æ€§å’Œå¯é æ€§ï¼Œä½†æ— æ³•ä¿è¯å…¶å®Œå…¨å…äºæ•…éšœã€ä¸­æ–­ã€é”™è¯¯æˆ–æ”»å‡»ã€‚å› æ­¤ï¼Œæœ¬å…¬å¸åœ¨æ­¤å£°æ˜ï¼šå¯¹äºæœ¬æœåŠ¡çš„å†…å®¹ã€å‡†ç¡®æ€§ã€å®Œæ•´æ€§ã€å¯é æ€§ã€é€‚ç”¨æ€§ä»¥åŠåŠæ—¶æ€§ä¸ä½œä»»ä½•é™ˆè¿°ã€ä¿è¯æˆ–æ‰¿è¯ºï¼Œä¸å¯¹æ‚¨ä½¿ç”¨æœ¬æœåŠ¡æ‰€äº§ç”Ÿçš„ä»»ä½•ç›´æ¥æˆ–é—´æ¥çš„æŸå¤±æˆ–æŸå®³æ‰¿æ‹…ä»»ä½•è´£ä»»ï¼›å¯¹äºæ‚¨é€šè¿‡æœ¬æœåŠ¡è®¿é—®çš„ç¬¬ä¸‰æ–¹ç½‘ç«™ã€åº”ç”¨ç¨‹åºã€äº§å“å’ŒæœåŠ¡ï¼Œä¸å¯¹å…¶å†…å®¹ã€å‡†ç¡®æ€§ã€å®Œæ•´æ€§ã€å¯é æ€§ã€é€‚ç”¨æ€§ä»¥åŠåŠæ—¶æ€§æ‰¿æ‹…ä»»ä½•è´£ä»»ï¼Œæ‚¨åº”è‡ªè¡Œæ‰¿æ‹…ä½¿ç”¨åæœäº§ç”Ÿçš„é£é™©å’Œè´£ä»»ï¼›å¯¹äºå› æ‚¨ä½¿ç”¨æœ¬æœåŠ¡è€Œäº§ç”Ÿçš„ä»»ä½•æŸå¤±ã€æŸå®³ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºç›´æ¥æŸå¤±ã€é—´æ¥æŸå¤±ã€åˆ©æ¶¦æŸå¤±ã€å•†èª‰æŸå¤±ã€æ•°æ®æŸå¤±æˆ–å…¶ä»–ç»æµæŸå¤±ï¼Œä¸æ‰¿æ‹…ä»»ä½•è´£ä»»ï¼Œå³ä½¿æœ¬å…¬å¸äº‹å…ˆå·²è¢«å‘ŠçŸ¥å¯èƒ½å­˜åœ¨æ­¤ç±»æŸå¤±æˆ–æŸå®³çš„å¯èƒ½æ€§ï¼›æˆ‘ä»¬ä¿ç•™ä¸æ—¶ä¿®æ”¹æœ¬å£°æ˜çš„æƒåˆ©ï¼Œå› æ­¤è¯·æ‚¨åœ¨ä½¿ç”¨æœ¬æœåŠ¡å‰å®šæœŸæ£€æŸ¥æœ¬å£°æ˜ã€‚å¦‚æœæ‚¨å¯¹æœ¬å£°æ˜æˆ–æœ¬æœåŠ¡å­˜åœ¨ä»»ä½•é—®é¢˜æˆ–ç–‘é—®ï¼Œè¯·è”ç³»æˆ‘ä»¬ã€‚

## æ¦‚è¿°
ComfyUIæ˜¯ æœ€å¼ºå¤§çš„å¼€æºèŠ‚ç‚¹å¼ç”Ÿæˆå¼AIåº”ç”¨ï¼Œæ”¯æŒåˆ›å»ºå›¾åƒã€è§†é¢‘åŠéŸ³é¢‘å†…å®¹ã€‚ä¾æ‰˜å‰æ²¿å¼€æºæ¨¡å‹å¯å®ç°è§†é¢‘ä¸å›¾åƒç”Ÿæˆã€‚
ä¾æ®å®˜æ–¹æ–‡æ¡£ï¼ŒComfyUIå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š
+ èŠ‚ç‚¹/å›¾å½¢/æµç¨‹å›¾ç•Œé¢ï¼Œç”¨äºå®éªŒå’Œåˆ›å»ºå¤æ‚çš„ç¨³å®šæ‰©æ•£å·¥ä½œæµç¨‹ï¼Œæ— éœ€ç¼–å†™ä»»ä½•ä»£ç ã€‚
+ å®Œå…¨æ”¯æŒ SD1.xã€SD2.x å’Œ SDXL
+ å¼‚æ­¥é˜Ÿåˆ—ç³»ç»Ÿ
+ å¤šé¡¹ä¼˜åŒ– åªé‡æ–°æ‰§è¡Œå·¥ä½œæµä¸­åœ¨ä¸¤æ¬¡æ‰§è¡Œä¹‹é—´å‘ç”Ÿå˜åŒ–çš„éƒ¨åˆ†ã€‚
+ å‘½ä»¤è¡Œé€‰é¡¹ï¼š--lowvram å¯ä½¿å…¶åœ¨ 3GB å†…å­˜ä»¥ä¸‹çš„ GPU ä¸Šè¿è¡Œï¼ˆåœ¨ä½å†…å­˜çš„ GPU ä¸Šè‡ªåŠ¨å¯ç”¨ï¼‰
+ å³ä½¿æ²¡æœ‰ GPU ä¹Ÿèƒ½ä½¿ç”¨ï¼š --cpuï¼ˆæ…¢é€Ÿï¼‰
+ å¯åŠ è½½ ckptã€safetensors å’Œ diffusers æ¨¡å‹/æ£€æŸ¥ç‚¹ã€‚ç‹¬ç«‹çš„ VAE å’Œ CLIP æ¨¡å‹ã€‚
+ åµŒå…¥/æ–‡æœ¬åæ¼”
+ Loras ï¼ˆå¸¸è§„ã€locon å’Œ lohaï¼‰
+ è¶…ç½‘ç»œ
+ ä»ç”Ÿæˆçš„ PNG æ–‡ä»¶åŠ è½½å®Œæ•´çš„å·¥ä½œæµï¼ˆå«ç§å­
+ ä»¥ Json æ–‡ä»¶ä¿å­˜/åŠ è½½å·¥ä½œæµã€‚
+ èŠ‚ç‚¹ç•Œé¢å¯ç”¨äºåˆ›å»ºå¤æ‚çš„å·¥ä½œæµç¨‹ï¼Œå¦‚ "Hires fix "æˆ–æ›´é«˜çº§çš„å·¥ä½œæµç¨‹ã€‚
+ åŒºåŸŸåˆæˆ
+ ä½¿ç”¨å¸¸è§„å’Œå†…ç»˜æ¨¡å‹è¿›è¡Œå†…ç»˜ã€‚
+ æ§åˆ¶ç½‘ç»œå’Œ T2I é€‚é…å™¨
+ å‡çº§æ¨¡å‹ï¼ˆESRGANã€ESRGAN å˜ä½“ã€SwinIRã€Swin2SR ç­‰ï¼‰
+ unCLIP æ¨¡å‹
+ GLIGEN
+ æ¨¡å‹åˆå¹¶ 
+ ä½¿ç”¨ TAESD è¿›è¡Œæ½œä¼é¢„è§ˆ 
+ å¯åŠ¨é€Ÿåº¦æå¿«ã€‚ 
+ å®Œå…¨ç¦»çº¿å·¥ä½œï¼šä¸ä¼šä¸‹è½½ä»»ä½•ä¸œè¥¿ã€‚ 
+ é…ç½®æ–‡ä»¶å¯è®¾ç½®æ¨¡å‹çš„æœç´¢è·¯å¾„ã€‚

## å‰ææ¡ä»¶
<font style="color:rgb(51, 51, 51);">éƒ¨ç½²ComfyUIç¤¾åŒºç‰ˆæœåŠ¡å®ä¾‹ï¼Œéœ€è¦å¯¹éƒ¨åˆ†é˜¿é‡Œäº‘èµ„æºè¿›è¡Œè®¿é—®å’Œåˆ›å»ºæ“ä½œã€‚å› æ­¤æ‚¨çš„è´¦å·éœ€è¦åŒ…å«å¦‚ä¸‹èµ„æºçš„æƒé™ã€‚</font><font style="color:rgb(51, 51, 51);"> </font>**<font style="color:rgb(51, 51, 51);">è¯´æ˜</font>**<font style="color:rgb(51, 51, 51);">ï¼šå½“æ‚¨çš„è´¦å·æ˜¯RAMè´¦å·æ—¶ï¼Œæ‰éœ€è¦æ·»åŠ æ­¤æƒé™ã€‚</font>

| <font style="color:rgb(51, 51, 51);">æƒé™ç­–ç•¥åç§°</font> | <font style="color:rgb(51, 51, 51);">å¤‡æ³¨</font> |
| --- | --- |
| <font style="color:rgb(51, 51, 51);">AliyunECSFullAccess</font> | <font style="color:rgb(51, 51, 51);">ç®¡ç†äº‘æœåŠ¡å™¨æœåŠ¡ï¼ˆECSï¼‰çš„æƒé™</font> |
| <font style="color:rgb(51, 51, 51);">AliyunVPCFullAccess</font> | <font style="color:rgb(51, 51, 51);">ç®¡ç†ä¸“æœ‰ç½‘ç»œï¼ˆVPCï¼‰çš„æƒé™</font> |
| <font style="color:rgb(51, 51, 51);">AliyunROSFullAccess</font> | <font style="color:rgb(51, 51, 51);">ç®¡ç†èµ„æºç¼–æ’æœåŠ¡ï¼ˆROSï¼‰çš„æƒé™</font> |
| <font style="color:rgb(51, 51, 51);">AliyunComputeNestUserFullAccess</font> | <font style="color:rgb(51, 51, 51);">ç®¡ç†è®¡ç®—å·¢æœåŠ¡ï¼ˆComputeNestï¼‰çš„ç”¨æˆ·ä¾§æƒé™</font> |


## è®¡è´¹è¯´æ˜
<font style="color:rgb(51, 51, 51);"> ç¤¾åŒºç‰ˆåœ¨è®¡ç®—å·¢éƒ¨ç½²çš„è´¹ç”¨ä¸»è¦æ¶‰åŠï¼š</font>

+ <font style="color:rgb(51, 51, 51);">æ‰€é€‰vCPUä¸å†…å­˜è§„æ ¼</font>
+ <font style="color:rgb(51, 51, 51);">ç³»ç»Ÿç›˜ç±»å‹åŠå®¹é‡</font>
+ <font style="color:rgb(51, 51, 51);">å…¬ç½‘å¸¦å®½</font>


## å‚æ•°è¯´æ˜
| <font style="color:rgb(51, 51, 51);">å‚æ•°ç»„</font> | <font style="color:rgb(51, 51, 51);">å‚æ•°é¡¹</font> | <font style="color:rgb(51, 51, 51);">è¯´æ˜</font> |
| --- | --- | --- |
| <font style="color:rgb(51, 51, 51);">æœåŠ¡å®ä¾‹</font> | <font style="color:rgb(51, 51, 51);">æœåŠ¡å®ä¾‹åç§°</font> | <font style="color:rgb(51, 51, 51);">é•¿åº¦ä¸è¶…è¿‡64ä¸ªå­—ç¬¦ï¼Œå¿…é¡»ä»¥è‹±æ–‡å­—æ¯å¼€å¤´ï¼Œå¯åŒ…å«æ•°å­—ã€è‹±æ–‡å­—æ¯ã€çŸ­åˆ’çº¿ï¼ˆ-ï¼‰å’Œä¸‹åˆ’çº¿ï¼ˆ_ï¼‰</font> |
| | <font style="color:rgb(51, 51, 51);">åœ°åŸŸ</font> | <font style="color:rgb(51, 51, 51);">æœåŠ¡å®ä¾‹éƒ¨ç½²çš„åœ°åŸŸ</font> |
| | <font style="color:rgb(51, 51, 51);">ä»˜è´¹ç±»å‹</font> | <font style="color:rgb(51, 51, 51);">èµ„æºçš„è®¡è´¹ç±»å‹ï¼šæŒ‰é‡ä»˜è´¹å’ŒåŒ…å¹´åŒ…æœˆ</font> |
| <font style="color:rgb(51, 51, 51);">ECSå®ä¾‹é…ç½®</font> | <font style="color:rgb(51, 51, 51);">å®ä¾‹ç±»å‹</font> | <font style="color:rgb(51, 51, 51);">å¯ç”¨åŒºä¸‹å¯ä»¥ä½¿ç”¨çš„å®ä¾‹è§„æ ¼</font> |
| <font style="color:rgb(51, 51, 51);">ç½‘ç»œé…ç½®</font> | <font style="color:rgb(51, 51, 51);">å¯ç”¨åŒº</font> | <font style="color:rgb(51, 51, 51);">ECSå®ä¾‹æ‰€åœ¨å¯ç”¨åŒº</font> |
| | <font style="color:rgb(51, 51, 51);">VPC ID</font> | <font style="color:rgb(51, 51, 51);">èµ„æºæ‰€åœ¨VPC</font> |
| | <font style="color:rgb(51, 51, 51);">äº¤æ¢æœºID</font> | <font style="color:rgb(51, 51, 51);">èµ„æºæ‰€åœ¨äº¤æ¢æœº</font> |


## éƒ¨ç½²æµç¨‹
1. è®¿é—®è®¡ç®—å·¢ [éƒ¨ç½²é“¾æ¥](https://computenest.console.aliyun.com/service/instance/create/cn-hangzhou?type=user&ServiceName=Comfy-UIç¤¾åŒºç‰ˆ)ï¼ŒæŒ‰æç¤ºå¡«å†™éƒ¨ç½²å‚æ•°
2. å¡«å†™å®ä¾‹å‚æ•°![](./img/param1.png)ï¼Œé€‰æ‹©ä½ æƒ³è´­ä¹°çš„æ–¹å¼å’Œå®ä¾‹ç±»å‹ã€‚
3. **æ³¨æ„** å¦‚æœæ‚¨æƒ³è¦ä½¿ç”¨å›¾ç”Ÿè§†é¢‘åŠŸèƒ½ï¼Œä¸ºäº†é™ä½çˆ†RAMå†…å­˜çš„å¯èƒ½ï¼Œè¯·é€‰æ‹©60Gä»¥ä¸Šçš„å†…å­˜è§„æ ¼+A10ä»¥ä¸Šçš„æ˜¾å¡è§„æ ¼ã€‚
3. æ ¹æ®éœ€æ±‚é€‰æ‹©æ–°å»ºä¸“ç”¨ç½‘ç»œæˆ–ç›´æ¥ä½¿ç”¨å·²æœ‰çš„ä¸“æœ‰ç½‘ç»œã€‚å¡«å†™å¯ç”¨åŒºå’Œç½‘ç»œå‚æ•°![](./img/param2.png)
5. ç‚¹å‡»ç«‹å³åˆ›å»ºï¼Œç­‰å¾…æœåŠ¡å®ä¾‹éƒ¨ç½²å®Œæˆ![](./img/param3.png)
6. æœåŠ¡å®ä¾‹éƒ¨ç½²å®Œæˆåï¼Œç‚¹å‡»å®ä¾‹IDè¿›å…¥åˆ°è¯¦æƒ…ç•Œé¢![](./img/serviceInstance2.png)
7. è®¿é—®æœåŠ¡å®ä¾‹çš„ä½¿ç”¨URLï¼Œè¿™é‡Œæˆ‘ä»¬é‡‡ç”¨å®‰å…¨ä»£ç†ç›´æ¥è®¿é—®ã€‚é¿å…æ‚¨çš„æ•°æ®æš´éœ²åˆ°å…¬ç½‘è¢«åˆ«äººè·å–![](./img/serviceInstance3.png)
8. è¿›å…¥ComfyUIä½¿ç”¨ç•Œé¢

## ä½¿ç”¨æµç¨‹
æœ¬æœåŠ¡å·²ç»å†…ç½®äº†ä¸¤ä¸ªå¯ä»¥ç›´æ¥ä½¿ç”¨çš„å·¥ä½œæµã€‚å…¶ä¸­æ¶‰åŠçš„æ’ä»¶å’Œæ¨¡å‹ä¹Ÿå·²ç»å‡†å¤‡å¥½ã€‚
### å›¾ç”Ÿè§†é¢‘æˆ–æ–‡ç”Ÿè§†é¢‘åŠŸèƒ½
1. åœ¨ä¸‹å›¾å¤„é€‰æ‹©æƒ³è¦çš„åŠŸèƒ½ã€‚å»ºè®®åªé€‰æ‹©ä¸€ç§è¿›è¡Œä½¿ç”¨ï¼Œé¿å…çˆ†å†…å­˜ã€‚![img.png](img/option.png)
2. æŒ‰å›¾ä¸­æŒ‡å¼•é€‰æ‹©å·¥ä½œæµä¾§æ ï¼Œé€‰æ‹©wans.jsonå¹¶æ‰“å¼€ã€‚![img.png](img/app2.png)
3. åœ¨æ­¤å¤„é€‰æ‹©ç¤ºä¾‹å›¾ç‰‡æˆ–é€‰æ‹©è‡ªå·±æœ¬æœºç”µè„‘ä¸Šä¼ ã€‚![img.png](img/app3.png)
4. åœ¨TextEncodeå¤„å¡«å†™æè¿°è¯ã€‚ä¸Šé¢éƒ¨åˆ†æ˜¯ä½ æƒ³è¦ç”Ÿæˆçš„å†…å®¹ï¼Œä¸‹é¢éƒ¨åˆ†æ˜¯ä½ ä¸æƒ³è¦ç”Ÿæˆçš„å†…å®¹ã€‚![img.png](img/prompt.png)
5. åœ¨ImageClip Encodeå¤„å¯è®¾ç½®å›¾ç‰‡çš„åˆ†è¾¨ç‡å’Œå¸§æ•°ã€‚æœ¬æ¨¡å‹æœ€é«˜å¯è®¾ç½®720*720ã€‚![img.png](img/definition.png)
6. å…¶ä½™å‚æ•°å¯å‚è€ƒå®˜ç½‘ï¼šhttps://comfyui-wiki.com/zh/interface/node-options  æˆ–ä»¥ä¸‹æ–‡æ¡£ï¼šhttps://github.com/kijai/ComfyUI-WanVideoWrapper/blob/main/readme.md

### æ–‡ç”Ÿå›¾åŠŸèƒ½
1. å·¥ä½œæµæ¡†å¤„é€‰æ‹©è¯¥å·¥ä½œæµã€‚![img.png](img/text2img.png)
2. è¾“å…¥ä½ æƒ³è¦çš„å†…å®¹ã€‚![img.png](img/text2img2.png)
3. è¿™é‡Œå¯ä»¥è¾“å…¥ä¸€äº›æ¯”è¾ƒææ€ªçš„å†…å®¹ï¼Œæ¯”å¦‚æˆ‘è¿™é‡Œæ˜¯å…³ç¾½å¤§æˆ˜ç™½é›ªå…¬ä¸»ã€‚
4. å¯ä»¥åœ¨æ­¤å¤„è®¾ç½®å›¾ç‰‡çš„åˆ†è¾¨ç‡å’Œå›¾ç‰‡çš„æ•°é‡ã€‚å¦‚æœæƒ³åŠ å¿«ç”Ÿäº§é€Ÿåº¦ï¼Œå¯å°†batch_sizeè®¾ç½®ä¸º1.![img.png](img/text2img3.png)
5. ç­‰å¾…å›¾ç‰‡çš„ç”Ÿæˆã€‚

### å›¾ç”Ÿå›¾åŠŸèƒ½
è®¿é—®æ¨¡ç‰ˆï¼Œæˆ–è‡ªå·±å¯¼å…¥å·¥ä½œæµä½¿ç”¨ã€‚![img2img.png](img%2Fimg2img.png)

## æ¨¡å‹ä¸‹è½½
1. æ¨èå‰å¾€é­”æ­ä¸‹è½½
2. æ¨¡å‹å­˜å‚¨è·¯å¾„ä¸ºï¼š/root/storage/models

## å†…ç½®æ¨¡å‹è¯´æ˜

### ğŸ“Š **Model Categories Overview**

| **Category** | **Directory** | **Total Size** | **Model Count** | **Primary Function** |
|--------------|---------------|----------------|-----------------|---------------------|
| Diffusion Models | `/diffusion_models` | 53GB | 6 models | Core image/video generation |
| Text Encoders | `/text_encoders` | 22GB | 2 models | Text understanding |
| CLIP Models | `/clip` | 17GB | 4 models | Vision-language understanding |
| Checkpoints | `/checkpoints` | 17GB | 1 model | Complete model checkpoints |
| UNET Models | `/unet` | 14GB | 1 model | Neural network architecture |
| VAE Models | `/vae` | 1.5GB | 5 models | Latent space processing |
| CLIP Vision | `/clip_vision` | 2.4GB | 1 model | Visual understanding |
| Face Restoration | `/facerestore_models` | 1.3GB | 4 models | Face enhancement |
| Video Interpolation | `/interpolation` | 824MB | 4 models | Frame interpolation |
| Content Safety | `/nsfw_detector` | 329MB | 1 model | Content moderation |
| Upscaling | `/upscale_models` | 192MB | 3 models | Image super-resolution |
| VAE Approximation | `/vae_approx` | 19MB | 4 models | Fast preview generation |
| Text Embeddings | `/embeddings` | 260KB | 2 models | Negative prompts |
| Configurations | `/configs` | 52KB | 11 files | Model configurations |

---

### ğŸ¯ **Diffusion Models** (`/diffusion_models`) - 53GB

| **Model Name** | **Size** | **Type** | **Parameters** | **Function** | **Best For** |
|----------------|----------|----------|----------------|--------------|--------------|
| `Wan2_1-I2V-14B-480P_fp8_e4m3fn.safetensors` | 16GB | Imageâ†’Video | 14B | Animate static images | Image animation |
| `Wan2_1-T2V-14B_fp8_e4m3fn.safetensors` | 14GB | Textâ†’Video | 14B | Generate videos from text | Text-to-video |
| `flux1-dev.safetensors` | 12GB | Textâ†’Image | - | Experimental image generation | Testing new features |
| `wan21_vace_1_3b.safetensors` | 6.7GB | Video Editing | 1.3B | Enhanced video editing | Professional editing |
| `wan2.1/Wan2_1-T2V-1_3B_fp8_e4m3fn.safetensors` | 1.4GB | Textâ†’Video | 1.3B | Fast video generation | Quick previews |

---

### ğŸ§  **Text Encoders** (`/text_encoders`) - 22GB

| **Model Name** | **Size** | **Format** | **Precision** | **Function** | **Best For** |
|----------------|----------|------------|---------------|--------------|--------------|
| `wan2.1/umt5-xxl-enc-bf16.safetensors` | 11GB | SafeTensors | BF16 | Multi-language text encoding | High-quality generation |
| `wan2.1/models_t5_umt5-xxl-enc-bf16.pth` | 11GB | PyTorch | BF16 | T5-based text encoding | PyTorch workflows |

---

### ğŸ¨ **CLIP Models** (`/clip`) - 17GB

| **Model Name** | **Size** | **Type** | **Precision** | **Function** | **Best For** |
|----------------|----------|----------|---------------|--------------|--------------|
| `t5xxl_fp16.safetensors` | 9.2GB | T5 Text Encoder | FP16 | Advanced text understanding | Complex prompts |
| `umt5_xxl_fp8_e4m3fn.safetensors` | 6.3GB | UMT5 Encoder | FP8 | Efficient text encoding | Resource optimization |
| `wan2.1/open-clip-xlm-roberta-large-vit-huge-14_visual_fp16.safetensors` | 1.2GB | Multilingual CLIP | FP16 | Cross-language vision | International content |
| `clip_l.safetensors` | 235MB | CLIP Language | - | Vision-language alignment | Standard workflows |

---

### ğŸ’¾ **Checkpoints** (`/checkpoints`) - 17GB

| **Model Name** | **Size** | **Type** | **Precision** | **Function** | **Best For** |
|----------------|----------|----------|---------------|--------------|--------------|
| `flux1-schnell-fp8.safetensors` | 17GB | Fast Image Gen | FP8 | Rapid image generation | Production workflows |

---

### ğŸ”§ **UNET Models** (`/unet`) - 14GB

| **Model Name** | **Size** | **Type** | **Quantization** | **Function** | **Best For** |
|----------------|----------|----------|------------------|--------------|--------------|
| `Wan2.1_14B_VACE-Q6_K.gguf` | 14GB | Video Editing | Q6_K | Professional video editing | High-quality editing |

---

### ğŸ”„ **VAE Models** (`/vae`) - 1.5GB

| **Model Name** | **Size** | **Type** | **Precision** | **Function** | **Best For** |
|----------------|----------|----------|---------------|--------------|--------------|
| `ae.safetensors` | 320MB | Standard VAE | - | Basic latent processing | General use |
| `vae-ft-mse-840000-ema-pruned.safetensors` | 320MB | Fine-tuned VAE | - | High-quality reconstruction | Quality workflows |
| `diffusion_pytorch_model.safetensors` | 320MB | Standard VAE | - | Broad compatibility | General compatibility |
| `wan2.1/Wan2_1_VAE_bf16.safetensors` | 243MB | Wan2.1 VAE | BF16 | Video-optimized processing | Video generation |
| `wan21_vace_vae.safetensors` | 243MB | VACE VAE | - | Video editing processing | Video editing |

---

### ğŸ‘ï¸ **CLIP Vision Models** (`/clip_vision`) - 2.4GB

| **Model Name** | **Size** | **Architecture** | **Training Data** | **Function** | **Best For** |
|----------------|----------|------------------|-------------------|--------------|--------------|
| `CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors` | 2.4GB | ViT-Huge-14 | LAION-2B | Visual understanding | High-quality analysis |

---

### ğŸ¬ **Video Interpolation Models** (`/interpolation`) - 824MB

#### GIMM-VFI Directory (`/interpolation/gimm-vfi` & `/interpolation/GIMM-VFI_safetensors`)

| **Model Name** | **Size** | **Type** | **Function** | **Best For** |
|----------------|----------|----------|--------------|--------------|
| `gimmvfi_f_arb_lpips_fp32.safetensors` | 117MB | Full VFI Model | Complete frame interpolation | Production workflows |
| `gimmvfi_r_arb_lpips_fp32.safetensors` | 76MB | Refinement Model | Frame quality enhancement | Quality improvement |
| `flowformer_sintel_fp32.safetensors` | 62MB | Motion Model | Advanced motion understanding | Complex motion |
| `raft-things_fp32.safetensors` | 21MB | Optical Flow | Motion estimation | Motion calculation |

---

### ğŸ” **Face Restoration Models** (`/facerestore_models`) - 1.3GB

| **Model Name** | **Size** | **Type** | **Function** | **Best For** |
|----------------|----------|----------|--------------|--------------|
| `codeformer-v0.1.0.pth` | 360MB | CodeFormer | Advanced face enhancement | Professional portraits |
| `GFPGANv1.4.pth` | 333MB | GFPGAN v1.4 | Improved face restoration | High-quality restoration |
| `GFPGANv1.3.pth` | 333MB | GFPGAN v1.3 | Face restoration | General face enhancement |
| `GPEN-BFR-512.onnx` | 272MB | GPEN (ONNX) | Real-time face restoration | Fast processing |

---

### â¬†ï¸ **Upscaling Models** (`/upscale_models`) - 192MB

| **Model Name** | **Size** | **Scale** | **Type** | **Function** | **Best For** |
|----------------|----------|-----------|----------|--------------|--------------|
| `8x_NMKD-Superscale_150000_G.pth` | 64MB | 8x | NMKD | Extreme upscaling | Maximum resolution |
| `4x_foolhardy_Remacri.pth` | 64MB | 4x | Enhanced ESRGAN | Sharp upscaling | General upscaling |
| `4x_NMKD-Siax_200k.pth` | 64MB | 4x | NMKD Siax | Alternative upscaling | Artistic enhancement |

---

### ğŸš« **Content Safety Models** (`/nsfw_detector`) - 329MB

| **Model Name** | **Size** | **Architecture** | **Function** | **Best For** |
|----------------|----------|------------------|--------------|--------------|
| `vit-base-nsfw-detector/model.safetensors` | 329MB | ViT-Base | Content moderation | Safety filtering |

**Additional Files:**
- `config.json` - Model configuration
- `preprocessor_config.json` - Input preprocessing
- `confusion_matrix.png` - Performance metrics

---

### âš¡ **VAE Approximation Models** (`/vae_approx`) - 19MB

| **Model Name** | **Size** | **Target** | **Function** | **Best For** |
|----------------|----------|------------|--------------|--------------|
| `taef1_decoder.pth` | 4.8MB | SD3/FLUX | Fast preview for SD3/FLUX | Modern models |
| `taesd3_decoder.pth` | 4.8MB | SD3 | Fast preview for SD3 | SD3 workflows |
| `taesdxl_decoder.pth` | 4.7MB | SDXL | Fast preview for SDXL | SDXL workflows |
| `taesd_decoder.pth` | 4.7MB | SD1.5 | Fast preview for SD1.5 | SD1.5 workflows |

---



## è´¦å·å¯†ç 
é»˜è®¤è´¦å·å’Œå¯†ç ä¸º:
1. è´¦å·ï¼šadmin
2. å¯†ç ï¼šadmin

### å¸¸è§é—®é¢˜
1. å‡ºç°æŸä¸ªèŠ‚ç‚¹ç±»å‹ä¸å­˜åœ¨ï¼Œé€šè¿‡managerå®‰è£…ç¼ºå°‘çš„èŠ‚ç‚¹ï¼Œå¹¶é‡å¯ã€‚![img_1.png](img/issue1.png)![img.png](img/issue2.png)