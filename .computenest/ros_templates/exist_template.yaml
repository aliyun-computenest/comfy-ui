ROSTemplateFormatVersion: '2015-09-01'
Description:
  en: Create ack Cluster And JumpBox Ecs, Deploy with kubectl -f yaml with new vpc
  zh-cn: 创建/选择ack集群和跳板机并使用kubectl部署(新建vpc)
Conditions:
  IfPPU:
    Fn::Equals:
      - Ref: GpuSeries
      - P16EN
  IfH20:
    Fn::Equals:
      - Ref: GpuSeries
      - GU8TF
  IsPublicEnabled:
    Fn::Equals:
      - Ref: SupportPublicAccess
      - true
  CreateNewOSS:
    Fn::Equals:
      - Ref: CreateOSS
      - true
Parameters:
  CreateOSS:
    Type: Boolean
    Label:
      en: Create New OSS Bucket
      zh-cn: 新建OSS Bucket
    Description:
      en: Whether to create a new OSS bucket or use an existing one
      zh-cn: 是否新建OSS存储桶或使用已有的
    Default: true
  ExistingOSSBucket:
    Type: String
    Label:
      en: Existing OSS Bucket Name
      zh-cn: 已有OSS存储桶名称
    Description:
      en: Name of the existing OSS bucket (required when not creating new OSS)
      zh-cn: 已有OSS存储桶的名称（不新建OSS时必填）
    Default: ""
    AssociationProperty: ALIYUN::OSS::Bucket::BucketName
    AssociationPropertyMetadata:
      Visible:
        Condition:
          Fn::Equals:
            - ${CreateOSS}
            - false
  ClusterId:
    Type: String
    Description:
      en: The ID of Kubernetes ClusterId in which application deployed.
      zh-cn: 部署应用程序的K8s集群ID
    AllowedPattern: '[0-9a-z]+$'
    Default: null
    Required: true
    Label:
      en: Kubernetes ClusterId
      zh-cn: K8s集群ID
    AssociationProperty: 'ALIYUN::CS::Cluster::ClusterId'
    AssociationPropertyMetadata:
      RegionId: '${RegionId}'
      Visible:
        Condition:
          Fn::Equals:
            - ${CreateAck}
            - false
  ModelSeries:
    Type: String
    Label:
      en: Model Series
      zh-cn: 模型系列
    Default: WanX-2.1(I2V-14B,T2V-14B,VACE-1.3B and I2V-1.3B)
    AllowedValues:
      - WanX-2.1(I2V-14B,T2V-14B,VACE-1.3B and I2V-1.3B)
      - WanX-2.2(I2V-14B,T2V-14B,ti2v-5B)
  GpuSeries:
    Type: String
    Label:
      en: GPU Series
      zh-cn: GPU系列
    Default: P16EN
    AllowedValues:
      - P16EN
      - GU8TF
  WhitelistConfirmation:
    Type: "String"
    Label:
      en: "Whitelist Confirmation"
      zh-cn: "白名单配置确认"
    AssociationProperty: "AlertCheckbox"
    AssociationPropertyMetadata:
      Description:
        zh-cn: |
          <strong>重要前置条件：</strong>
          使用本服务前，请确保已为P16EN/GU8TF/L20实例正确配置白名单规则，请联系客服、销售或提交工单加白。
          <a href="https://smartservice.console.aliyun.com/service/create-ticket" target="_blank">提交工单</a>
        en: |
          <strong>Important Preconditions:</strong>
          Before using this service, please ensure that the whitelist rule for P16EN/GU8TF/L20 instances is correctly configured. Contact customer service, sales, or submit a ticket to add the whitelist.
          <a href="https://smartservice.console.aliyun.com/service/create-ticket" target="_blank">Submit a ticket</a>
      ConfirmText:
        zh-cn: "我已确认完成白名单配置"
        en: "I have confirmed the whitelist configuration"
      Alert: true
      Type: "warning"
      MustChecked: true
  SupportPublicAccess:
    Type: Boolean
    Label:
      zh-cn: 支持公网访问
      en: Support Public Access
Resources:
  KubernetesCluster:
    Type: DATASOURCE::CS::KubernetesCluster
    Properties:
      ClusterId:
        Ref: ClusterId
  ClusterUserKubeconfig:
    Type: DATASOURCE::CS::ClusterUserKubeconfig
    Properties:
      ClusterId:
        Ref: ClusterId
      # 可选参数
      PrivateIpAddress: true  # 是否获取内网访问凭证（默认公网）
  RandomPassword:
    Type: ALIYUN::RandomString
    Properties:
      length: 11
      character_classes:
        - class: "lowercase"
          min: 4
        - class: "uppercase"
          min: 4
        - class: "digits"
          min: 2
      character_sequences:
        - sequence: "!@#$^*-+="
  OSSBucket:
    Type: 'ALIYUN::OSS::Bucket'
    Condition: CreateNewOSS
    Properties:
      DeletionForce: true
      BucketName:
        Ref: ALIYUN::StackName
  OSSRamUser:
    DependsOn: OSSBucket
    Type: ALIYUN::RAM::User
    Properties:
      UserName:
        Ref: ALIYUN::StackName
      Policies:
        - PolicyName:
            Ref: ALIYUN::StackName
          PolicyDocument:
            Statement:
              - Action:
                  - oss:*
                Effect: Allow
                Resource:
                  - Fn::Sub:
                      - "acs:oss:*:*:${BucketName}"
                      - BucketName:
                          Fn::If:
                            - CreateNewOSS
                            - Fn::GetAtt:
                                - OSSBucket
                                - Name
                            - Ref: ExistingOSSBucket
                  - Fn::Sub:
                      - "acs:oss:*:*:${BucketName}/*"
                      - BucketName:
                          Fn::If:
                            - CreateNewOSS
                            - Fn::GetAtt:
                                - OSSBucket
                                - Name
                            - Ref: ExistingOSSBucket
            Version: '1'
  AccessKey:
    DependsOn: OSSRamUser
    Type: ALIYUN::RAM::AccessKey
    Properties:
      UserName:
        Ref: ALIYUN::StackName
  EcsInstanceJumpBox:
    Type: ALIYUN::ECS::InstanceGroup
    Properties:
      InstanceName:
        Fn::Join:
          - '-'
          - - Ref: ALIYUN::StackName
            - jumpbox
      ImageId:
        Fn::FindInMap:
          - ModelMapping
          - ModelImageMap
          - Ref: ModelSeries
      InstanceType: 'ecs.u1-c1m2.xlarge'
      ZoneId:
        Fn::GetAtt:
          - KubernetesCluster
          - ZoneId
      VpcId:
        Fn::GetAtt:
          - KubernetesCluster
          - VpcId
      VSwitchId:
        Fn::GetAtt:
          - KubernetesCluster
          - VSwitchId
      SecurityGroupId:
        Fn::GetAtt:
          - KubernetesCluster
          - SecurityGroupId
      AllocatePublicIP: false
      Password:
        Ref: RandomPassword
      MaxAmount: 1
      InstanceChargeType: PostPaid
      SystemDiskSize: 250
      SystemDiskCategory: cloud_essd
  RunAllCommands:
    Type: ALIYUN::ECS::RunCommand
    DependsOn:
      - EcsInstanceJumpBox
      - RandomApiKey
    Properties:
      Sync: true
      Type: RunShellScript
      InstanceIds:
        - Fn::Select:
            - 0
            - Fn::GetAtt:
                - EcsInstanceJumpBox
                - InstanceIds
      Timeout: '86400'  # 延长超时时间
      CommandContent:
        Fn::Sub:
          - |
            #!/bin/bash
            # 设置日志输出：普通日志记录到文件，错误信息同时输出到终端和文件
            exec > >(cat >>/tmp/deploy.log) 2> >(tee -a /tmp/deploy.log >&2)
            set -e  # 遇到错误立即终止

            # --- 1. 安装基础工具 ---
            echo "Checking kubectl installation..."
            if ! command -v kubectl &> /dev/null; then
              echo "Installing kubectl..."
              wget {{ computenest::file::kubectl }} -O kubectl >> /tmp/deploy.log 2>&1
              install -o root -g root -m 0755 kubectl /usr/bin/kubectl >> /tmp/deploy.log 2>&1
              chmod +x /usr/bin/kubectl
              echo "Configuring kubectl..."
              mkdir -p ~/.kube
              echo '${kubeConfig}' >> ~/.kube/config
              sleep 10
            else
              echo "kubectl already installed."
            fi

            echo "Checking ossutil installation..."
            if ! command -v ossutil &> /dev/null; then
              echo "Configuring OSS..."
              sudo -v >> /tmp/deploy.log 2>&1

              # 安装ossutil2.0
              wget {{ computenest::file::ossutil }} -O ossutil.zip >> /tmp/deploy.log 2>&1
              unzip ossutil.zip >> /tmp/deploy.log 2>&1
              cd ossutil-2.1.0-linux-amd64
              chmod 755 ossutil >> /tmp/deploy.log 2>&1
              mv -f ossutil /usr/local/bin/ && sudo ln -sf /usr/local/bin/ossutil /usr/bin/ossutil >> /tmp/deploy.log 2>&1
              ossutil >> /tmp/deploy.log 2>&1
            else
              echo "ossutil already installed."
            fi
            cd ..
            cat >> /usr/bin/oss.cfg <<EOF
            [Credentials]
            endpoint = oss-${regionId}-internal.aliyuncs.com
            accessKeyID = ${accessKeyId}
            accessKeySecret = ${accessKeySecret}
            region = ${regionId}
            EOF

            sysctl -w net.ipv4.tcp_window_scaling=1
            sysctl -w net.core.rmem_max=16777216
            sysctl -w net.core.wmem_max=16777216
            ossutil --config-file /usr/bin/oss.cfg cp -r /root/storage/ oss://${bucketName}/llm-model/ --ignore-existing | tee download.log


            # --- 3. 下载并解压所有 YAML 文件 ---
            echo "Downloading and extracting YAML templates..."
            if [ ! -f "wanx-resource.tar.gz" ]; then
              echo "Downloading YAML files..."
              wget {{ computenest::file::wanx-resource }} -O wanx-resource.tar.gz >> /tmp/deploy.log 2>&1
            else
              echo "YAML tar file already exists."
            fi

            if [ ! -d "wanx-resource" ]; then
              echo "Extracting YAML files..."
              tar -xzvf wanx-resource.tar.gz >> /tmp/deploy.log 2>&1
              cd wanx-resource || exit
            else
              echo "YAML directory already exists."
              cd wanx-resource || exit
            fi

            echo "Deploying pre-requisites..."
            sed -i "s|\${!AccessKeyId}|${accessKeyId}|g" pre-deploy-application.yaml
            sed -i "s|\${!AccessKeySecret}|${accessKeySecret}|g" pre-deploy-application.yaml
            cat pre-deploy-application.yaml
            # 检查是否已部署
             kubectl --kubeconfig ~/.kube/config apply -f pre-deploy-application.yaml --validate=false

              echo "Pre-requisites already deployed."


            echo "Deploying pvc application..."
            sed -i "s|\${!RegionId}|${regionId}|g" oss-pv-pvc.yaml
            sed -i "s|\${!BucketName}|${bucketName}|g" oss-pv-pvc.yaml
            kubectl apply -f oss-pv-pvc.yaml --validate=false


            # --- 5. 部署模型 ---
            echo "Deploying model..."
            case "${GpuSeries}" in
              "P16EN"|"ppu")
              CONFIG_FILE="wanx21-application-ppu.yaml"
            echo "检测到PPU系列GPU，使用配置文件: ${!CONFIG_FILE}"
              ;;
              "GU8TF")
              CONFIG_FILE="wanx21-application-h20.yaml"
              echo "检测到GU8TF系列GPU，使用配置文件: ${!CONFIG_FILE}"
              ;;
              *)
            echo "错误: 不支持的GPU系列 '${GpuSeries}'"
            echo "支持的GPU系列: GU8TF, P16EN"
              exit 1
              ;;
              esac            
            cat ${!CONFIG_FILE} && kubectl apply -f ${!CONFIG_FILE} --validate=false
            echo "Monitoring deployment: $DEPLOYMENT"
            NAMESPACE="default"
            MAX_ATTEMPTS=300
            INTERVAL=20
            SUCCESS=false
            for ((i=1; i<=MAX_ATTEMPTS; i++)); do
              # 首先检查 Deployment 是否存在
              if ! kubectl get deployment comfyui -n "$NAMESPACE" &>/dev/null; then
                echo "Deployment comfyui does not exist! (Attempt $i/$MAX_ATTEMPTS)"
                sleep $INTERVAL
                continue
              fi
              POD=$(kubectl get pods -n "$NAMESPACE" -l app="comfyui" -o jsonpath='{.items[0].metadata.name}')
              if [ -z "$POD" ]; then
                  echo "Waiting for pod creation... ($i/$MAX_ATTEMPTS)"
              else
                  CONTAINER_INSTANCE_STATUS=$(kubectl get pod "$POD" -n "$NAMESPACE" -o jsonpath='{.status.conditions[?(@.type=="ContainerInstanceCreated")].status}' 2>/dev/null)
                  CONTAINER_INSTANCE_REASON=$(kubectl get pod "$POD" -n "$NAMESPACE" -o jsonpath='{.status.conditions[?(@.type=="ContainerInstanceCreated")].reason}' 2>/dev/null)

                  if [[ "$CONTAINER_INSTANCE_STATUS" == "False" ]]; then
                    if [[ "$CONTAINER_INSTANCE_REASON" == *"FailedScheduling"* ]]; then
                      echo "Error: ContainerInstanceCreated failed due to scheduling failure!"
                      echo "Pod $POD is in phase: $PHASE (Attempt $i/$MAX_ATTEMPTS)"
                      echo "Exiting due to scheduling error."
                      SUCCESS=false
                      break
                    elif [[ "$CONTAINER_INSTANCE_REASON" == "FeatureGetNoPermission" ]]; then
                      echo "Error: ContainerInstanceCreated failed due to permission issue: FeatureGetNoPermission"
                      echo "Pod $POD is in phase: $PHASE (Attempt $i/$MAX_ATTEMPTS)"
                      echo "请检查 GPU 资源访问权限： GU8TF,P16EN 实例是否已正确配置白名单？"
                      echo "Exiting due to permission error."
                      SUCCESS=false
                      break
                    fi
                  fi

                  READY=$(kubectl get pod "$POD" -n "$NAMESPACE" -o jsonpath='{.status.containerStatuses[0].ready}')
                  PHASE=$(kubectl get pod "$POD" -n "$NAMESPACE" -o jsonpath='{.status.phase}')
                  if [[ "$READY" == "true" && "$PHASE" == "Running" ]]; then
                      echo "Pod $POD is ready!"
                      SUCCESS=true
                      break
                  else
                      echo "Pod $POD status: $PHASE (Attempt $i/$MAX_ATTEMPTS)"
                  fi
              fi
              sleep $INTERVAL
            done

              # 处理结果
            if [ "$SUCCESS" = "true" ]; then
                echo "Deployment succeeded"
            else
                echo "GPU库存不足，Pod拉起失败" >&2
                echo "Pod 状态信息：" >&2
                kubectl get pod "$POD" -n "$NAMESPACE" -o jsonpath='{range .status.containerStatuses[*]}Container: {.name} | Ready: {.ready} | State: {.state}{"\n"}{end}' >&2 || true                                                                                       
                echo "最近事件：" >&2
                kubectl get events --field-selector involvedObject.name="$POD" -n "$NAMESPACE" --sort-by='.lastTimestamp' -o jsonpath='{range .items[*]}{.lastTimestamp} {.reason} {.message}{"\n"}{end}' >&2 || true
                exit 1
            fi

            # --- 6. 创建服务（私有/公网）---
            echo "Creating services..."
            cat private-service.yaml
            if ! kubectl --kubeconfig ~/.kube/config get service svc-private -n "$NAMESPACE" &> /dev/null; then
              kubectl --kubeconfig ~/.kube/config apply -f private-service.yaml --validate=false
            else
              echo "Private service already exists."
            fi

            if [ "${supportPublicAccess}" = "True" ]; then
              cat public-service.yaml
              if ! kubectl --kubeconfig ~/.kube/config get service svc-public -n "$NAMESPACE" &> /dev/null; then
                kubectl --kubeconfig ~/.kube/config apply -f public-service.yaml --validate=false
              else
                echo "Public service already exists."
              fi
            fi

            # --- 7. 检测Private Service是否正常（最大15min）---
            # 新增：获取 Private Service 的 LoadBalancer IP
            MAX_ATTEMPTS=90
            INTERVAL=10
            SERVICE_NAME="svc-private"
            PRIVATE_IP=""
            for ((i=1; i<=MAX_ATTEMPTS; i++)); do
              PRIVATE_IP=$(kubectl get service "$SERVICE_NAME" -n "$NAMESPACE" -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
              if [[ -n "$PRIVATE_IP" && "$PRIVATE_IP" != "<pending>" ]]; then
                echo "Private Service IP: $PRIVATE_IP" >&2
                break
              else
                echo "Waiting for IP... (Attempt $i/$MAX_ATTEMPTS)" >&2
                sleep $INTERVAL
              fi
            done

            if [[ -z "$PRIVATE_IP" || "$PRIVATE_IP" == "<pending>" ]]; then
              echo "Failed to get Private Service IP after $MAX_ATTEMPTS attempts" >&2
              exit 1
            fi

          - kubeConfig:
              Fn::GetAtt:
                - ClusterUserKubeconfig
                - Config
            GpuSeries:
              Ref: GpuSeries
            regionId:
              Ref: ALIYUN::Region
            bucketName:
              Fn::GetAtt:
                - OSSBucket
                - Name
            supportPublicAccess:
              Ref: SupportPublicAccess
            accessKeyId:
              Fn::GetAtt:
                - AccessKey
                - AccessKeyId
            accessKeySecret:
              Fn::GetAtt:
                - AccessKey
                - AccessKeySecret
  RandomApiKey:
    Type: ALIYUN::RandomString
    Properties:
      length: 29
      character_classes:
        - class: lowercase
          min: 1
        - class: digits
          min: 1

  PrivateIngressResources:
    Type: DATASOURCE::CS::ClusterApplicationResources
    DependsOn:
      - RunAllCommands
    Properties:
      Namespace: default
      Kind: Service
      FirstMatch: True
      ApiVersion: v1
      JsonPath: $.status.loadBalancer.ingress[0].ip
      ClusterId:
        Fn::GetAtt:
          - KubernetesCluster
          - ClusterId
      Name: svc-private
  PublicIngressResources:
    Type: DATASOURCE::CS::ClusterApplicationResources
    DependsOn:
      - RunAllCommands
    Condition: IsPublicEnabled
    Properties:
      Namespace: default
      Kind: Service
      FirstMatch: True
      ApiVersion: v1
      JsonPath: $.status.loadBalancer.ingress[0].ip
      ClusterId:
        Fn::GetAtt:
          - KubernetesCluster
          - ClusterId
      Name: svc-public
Mappings:
  ModelMapping:
    ModelImageMap:
      'WanX-2.1(I2V-14B,T2V-14B,VACE-1.3B and I2V-1.3B)': ecs_image-comfy-ui
      'WanX-2.2(I2V-14B,T2V-14B,ti2v-5B)': ecsImage-wanx22
    ModelDiskSizeMap:
      'WanX-2.1(I2V-14B,T2V-14B,VACE-1.3B and I2V-1.3B)': 250
      'WanX-2.2(I2V-14B,T2V-14B,ti2v-5B)': 450

Outputs:
  comfyui_address:
    Label: 内网地址
    Value:
      Fn::Sub:
        - 'http://${PrivateIp}:8188/'
        - PrivateIp:
            Fn::GetAtt:
              - PrivateIngressResources
              - Response
  公网地址:
    Label: 公网地址
    Condition: IsPublicEnabled
    Value:
      Fn::Sub:
        - 'http://${PublicIp}:8188/'
        - PublicIp:
            Fn::GetAtt:
              - PublicIngressResources
              - Response
  InstancePassword:
    NoEcho: 'True'
    Label:
      en: Ecs Instance password
      zh-cn: ECS实例密码
    Description:
      en: Initial instance password
      zh-cn: ECS实例密码
    Value:
      Fn::GetAtt:
        - RandomPassword
        - value
Metadata:
  ALIYUN::ROS::Interface:
    ParameterGroups:
      - Parameters:
          - WhitelistConfirmation
        Label:
          en: Whitelist Confirmation
          zh-cn: 白名单确认
      - Parameters:
          - ClusterId
          - CreateOSS
          - ExistingOSSBucket
        Label:
          en: Basic Configuration
          zh-cn: 基础资源配置
      - Parameters:
          - ModelSeries
          - GpuSeries
          - SupportPublicAccess
        Label:
          en: Model Config
          zh-cn: 模型配置